{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"Graph utilities.\"\"\"\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from os import path\n",
    "from time import time\n",
    "from glob import glob\n",
    "from six.moves import range, zip, zip_longest\n",
    "from six import iterkeys\n",
    "from collections import defaultdict, Iterable\n",
    "from multiprocessing import cpu_count\n",
    "import random\n",
    "import collections\n",
    "from random import shuffle\n",
    "from itertools import product,permutations\n",
    "from scipy.io import loadmat\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(\"deepwalk\")\n",
    "\n",
    "\n",
    "__author__ = \"Bryan Perozzi\"\n",
    "__email__ = \"bperozzi@cs.stonybrook.edu\"\n",
    "\n",
    "LOGFORMAT = \"%(asctime).19s %(levelname)s %(filename)s: %(lineno)s %(message)s\"\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, id, name, type='user'):\n",
    "        self.id = str(id)\n",
    "        self.neighbors = []\n",
    "        self.name = name\n",
    "        self.type = type\n",
    "        self.rating = {}\n",
    "\n",
    "class Movie(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.director = None\n",
    "        self.actors = [] \n",
    "        self.genres = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Graph(defaultdict):\n",
    "  \"\"\"Efficient basic implementation of nx `Graph' â€“ Undirected graphs with self loops\"\"\"  \n",
    "  def __init__(self):\n",
    "    super(Graph, self).__init__(list)\n",
    "\n",
    "  def nodes(self):\n",
    "    return self.keys()\n",
    "\n",
    "  def adjacency_iter(self):\n",
    "    return self.iteritems()\n",
    "\n",
    "  def subgraph(self, nodes={}):\n",
    "    subgraph = Graph()\n",
    "    \n",
    "    for n in nodes:\n",
    "      if n in self:\n",
    "        subgraph[n] = [x for x in self[n] if x in nodes]\n",
    "        \n",
    "    return subgraph\n",
    "\n",
    "  def make_undirected(self):\n",
    "  \n",
    "    t0 = time()\n",
    "\n",
    "    for v in self.keys():\n",
    "      for other in self[v]:\n",
    "        if v != other:\n",
    "          self[other].append(v)\n",
    "    \n",
    "    t1 = time()\n",
    "    logger.info('make_directed: added missing edges {}s'.format(t1-t0))\n",
    "\n",
    "    self.make_consistent()\n",
    "    return self\n",
    "\n",
    "  def make_consistent(self):\n",
    "    t0 = time()\n",
    "    for k in iterkeys(self):\n",
    "      self[k] = list(sorted(set(self[k])))\n",
    "    \n",
    "    t1 = time()\n",
    "    logger.info('make_consistent: made consistent in {}s'.format(t1-t0))\n",
    "\n",
    "    self.remove_self_loops()\n",
    "\n",
    "    return self\n",
    "\n",
    "  def remove_self_loops(self):\n",
    "\n",
    "    removed = 0\n",
    "    t0 = time()\n",
    "\n",
    "    for x in self:\n",
    "      if x in self[x]: \n",
    "        self[x].remove(x)\n",
    "        removed += 1\n",
    "    \n",
    "    t1 = time()\n",
    "\n",
    "    logger.info('remove_self_loops: removed {} loops in {}s'.format(removed, (t1-t0)))\n",
    "    return self\n",
    "\n",
    "  def check_self_loops(self):\n",
    "    for x in self:\n",
    "      for y in self[x]:\n",
    "        if x == y:\n",
    "          return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "  def has_edge(self, v1, v2):\n",
    "    if v2 in self[v1] or v1 in self[v2]:\n",
    "      return True\n",
    "    return False\n",
    "\n",
    "  def degree(self, nodes=None):\n",
    "    if isinstance(nodes, Iterable):\n",
    "      return {v:len(self[v]) for v in nodes}\n",
    "    else:\n",
    "      return len(self[nodes])\n",
    "\n",
    "  def order(self):\n",
    "    \"Returns the number of nodes in the graph\"\n",
    "    return len(self)    \n",
    "\n",
    "  def number_of_edges(self):\n",
    "    \"Returns the number of nodes in the graph\"\n",
    "    return sum([self.degree(x) for x in self.keys()])/2\n",
    "\n",
    "  def number_of_nodes(self):\n",
    "    \"Returns the number of nodes in the graph\"\n",
    "    return order()\n",
    "\n",
    "  def random_walk(self, path_length, alpha=0, rand=random.Random(), start=None):\n",
    "    \"\"\" Returns a truncated random walk.\n",
    "\n",
    "        path_length: Length of the random walk.\n",
    "        alpha: probability of restarts.\n",
    "        start: the start node of the random walk.\n",
    "    \"\"\"\n",
    "    G = self\n",
    "    if start:\n",
    "      path = [start]\n",
    "    else:\n",
    "      # Sampling is uniform w.r.t V, and not w.r.t E\n",
    "      path = [rand.choice(G.keys())]\n",
    "\n",
    "    while len(path) < path_length:\n",
    "      cur = path[-1]\n",
    "      if len(G[cur]) > 0:\n",
    "        if rand.random() >= alpha:\n",
    "          path.append(rand.choice(G[cur]))\n",
    "        else:\n",
    "          path.append(path[0])\n",
    "      else:\n",
    "        break\n",
    "    return path\n",
    "\n",
    "# TODO add build_walks in here\n",
    "\n",
    "def build_deepwalk_corpus(G, num_paths, path_length, alpha=0,\n",
    "                      rand=random.Random(0)):\n",
    "  walks = []\n",
    "\n",
    "  nodes = list(G.nodes())\n",
    "  \n",
    "  for cnt in range(num_paths):\n",
    "    rand.shuffle(nodes)\n",
    "    for node in nodes:\n",
    "      walks.append(G.random_walk(path_length, rand=rand, alpha=alpha, start=node))\n",
    "  \n",
    "  return walks\n",
    "\n",
    "def build_deepwalk_corpus_iter(G, num_paths, path_length, alpha=0,\n",
    "                      rand=random.Random(0)):\n",
    "  walks = []\n",
    "\n",
    "  nodes = list(G.nodes())\n",
    "\n",
    "  for cnt in range(num_paths):\n",
    "    rand.shuffle(nodes)\n",
    "    for node in nodes:\n",
    "      yield G.random_walk(path_length, rand=rand, alpha=alpha, start=node)\n",
    "\n",
    "\n",
    "def clique(size):\n",
    "    return from_adjlist(permutations(range(1,size+1)))\n",
    "\n",
    "\n",
    "# http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks-in-python\n",
    "def grouper(n, iterable, padvalue=None):\n",
    "    \"grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\"\n",
    "    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)\n",
    "\n",
    "def parse_adjacencylist(f):\n",
    "  adjlist = []\n",
    "  for l in f:\n",
    "    if l and l[0] != \"#\":\n",
    "      introw = [int(x) for x in l.strip().split()]\n",
    "      row = [introw[0]]\n",
    "      row.extend(set(sorted(introw[1:])))\n",
    "      adjlist.extend([row])\n",
    "  \n",
    "  return adjlist\n",
    "\n",
    "def parse_adjacencylist_unchecked(f):\n",
    "  adjlist = []\n",
    "  for l in f:\n",
    "    if l and l[0] != \"#\":\n",
    "      adjlist.extend([[int(x) for x in l.strip().split()]])\n",
    "  \n",
    "  return adjlist\n",
    "\n",
    "def load_adjacencylist(file_, undirected=False, chunksize=10000, unchecked=True):\n",
    "\n",
    "  if unchecked:\n",
    "    parse_func = parse_adjacencylist_unchecked\n",
    "    convert_func = from_adjlist_unchecked\n",
    "  else:\n",
    "    parse_func = parse_adjacencylist\n",
    "    convert_func = from_adjlist\n",
    "\n",
    "  adjlist = []\n",
    "\n",
    "  t0 = time()\n",
    "\n",
    "  with open(file_) as f:\n",
    "    with ProcessPoolExecutor(max_workers=cpu_count()) as executor:\n",
    "      total = 0 \n",
    "      for idx, adj_chunk in enumerate(executor.map(parse_func, grouper(int(chunksize), f))):\n",
    "          adjlist.extend(adj_chunk)\n",
    "          total += len(adj_chunk)\n",
    "  \n",
    "  t1 = time()\n",
    "\n",
    "  logger.info('Parsed {} edges with {} chunks in {}s'.format(total, idx, t1-t0))\n",
    "\n",
    "  t0 = time()\n",
    "  G = convert_func(adjlist)\n",
    "  t1 = time()\n",
    "\n",
    "  logger.info('Converted edges to graph in {}s'.format(t1-t0))\n",
    "\n",
    "  if undirected:\n",
    "    t0 = time()\n",
    "    G = G.make_undirected()\n",
    "    t1 = time()\n",
    "    logger.info('Made graph undirected in {}s'.format(t1-t0))\n",
    "\n",
    "  return G \n",
    "\n",
    "\n",
    "def load_edgelist(file_, undirected=True):\n",
    "  G = Graph()\n",
    "  with open(file_) as f:\n",
    "    for l in f:\n",
    "      x, y = l.strip().split()[:2]\n",
    "      x = int(x)\n",
    "      y = int(y)\n",
    "      G[x].append(y)\n",
    "      if undirected:\n",
    "        G[y].append(x)\n",
    "  \n",
    "  G.make_consistent()\n",
    "  return G\n",
    "\n",
    "\n",
    "def load_matfile(file_, variable_name=\"network\", undirected=True):\n",
    "  mat_varables = loadmat(file_)\n",
    "  mat_matrix = mat_varables[variable_name]\n",
    "\n",
    "  return from_numpy(mat_matrix, undirected)\n",
    "\n",
    "\n",
    "def from_networkx(G_input, undirected=True):\n",
    "    G = Graph()\n",
    "\n",
    "    for idx, x in enumerate(G_input.nodes_iter()):\n",
    "        for y in iterkeys(G_input[x]):\n",
    "            G[x].append(y)\n",
    "\n",
    "    if undirected:\n",
    "        G.make_undirected()\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "def from_numpy(x, undirected=True):\n",
    "    G = Graph()\n",
    "\n",
    "    if issparse(x):\n",
    "        cx = x.tocoo()\n",
    "        for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "            G[i].append(j)\n",
    "    else:\n",
    "      raise Exception(\"Dense matrices not yet supported.\")\n",
    "\n",
    "    if undirected:\n",
    "        G.make_undirected()\n",
    "\n",
    "    G.make_consistent()\n",
    "    return G\n",
    "\n",
    "\n",
    "def from_adjlist(adjlist):\n",
    "    G = Graph()\n",
    "    \n",
    "    for row in adjlist:\n",
    "        node = row[0]\n",
    "        neighbors = row[1:]\n",
    "        G[node] = list(sorted(set(neighbors)))\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "def from_adjlist_unchecked(adjlist):\n",
    "    G = Graph()\n",
    "    \n",
    "    for row in adjlist:\n",
    "        node = str(row[0])\n",
    "        neighbors = map(str, row[1:])\n",
    "        G[node] = neighbors\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_movie_data():\n",
    "    # Movie data files used for building the graph\n",
    "    movies_directors_filename = \"./data/movie_directors.dat\"\n",
    "    movies_actors_filename = \"./data/movie_actors.dat\"\n",
    "    movies_genres_filename = \"./data/movie_genres.dat\"\n",
    "    movies_filename = \"./data/movies.dat\"\n",
    "    \n",
    "    # Load the data about the movies into a dictionary\n",
    "    # The dictionary maps a movie ID to a movie object\n",
    "    # Also store the unique directors, actors, and genres\n",
    "    movies = {}\n",
    "    with open(movies_filename, \"r\") as fin:\n",
    "        fin.next()  # burn metadata line\n",
    "        for line in fin:\n",
    "            m_id, name = line.strip().split()[:2]\n",
    "            movies[\"m\"+m_id] = Movie(name)\n",
    "    \n",
    "    directors = set([])\n",
    "    with open(movies_directors_filename, \"r\") as fin:\n",
    "        fin.next()  # burn metadata line\n",
    "        for line in fin:\n",
    "            m_id, director = line.strip().split()[:2]\n",
    "            if \"m\"+m_id in movies:\n",
    "                movies[\"m\"+m_id].director = director\n",
    "            directors.add(director)\n",
    "    \n",
    "    actors = set([])\n",
    "    with open(movies_actors_filename, \"r\") as fin:\n",
    "        fin.next()  # burn metadata line\n",
    "        for line in fin:\n",
    "            m_id, actor = line.strip().split()[:2]\n",
    "            if \"m\"+m_id in movies:\n",
    "                movies[\"m\"+m_id].actors.append(actor)\n",
    "            actors.add(actor)\n",
    "    \n",
    "    genres = set([])\n",
    "    with open(movies_genres_filename, \"r\") as fin:\n",
    "        fin.next()  # burn metadata line\n",
    "        for line in fin:\n",
    "            m_id, genre = line.strip().split()\n",
    "            if \"m\"+m_id in movies:\n",
    "                movies[\"m\"+m_id].genres.append(genre)\n",
    "            genres.add(genre)\n",
    "\n",
    "    return movies, directors, actors, genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjlist_file = open(\"./out.adj\", 'w')\n",
    "node_list_file = open(\"./nodelist.txt\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './data/train_user_ratings.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ab8a300a182b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/train_user_ratings.dat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# burn metadata line\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: './data/train_user_ratings.dat'"
     ]
    }
   ],
   "source": [
    "# Load all the ratings for every user into a dictionary\n",
    "    # The dictionary maps a user to a list of (movie, rating) pairs\n",
    "    #   e.g., ratings[75] = [(3,1), (32,4.5), ...]\n",
    "num_ratings = 0\n",
    "ratings = collections.defaultdict(dict)\n",
    "with open(\"./data/train_user_ratings.dat\", \"r\") as fin:\n",
    "    fin.next()  # burn metadata line\n",
    "    for line in fin:\n",
    "        ls = line.strip().split(\"\\t\")\n",
    "        user, movie, rating = ls[:3]\n",
    "        rating = str(int(round(float(rating))))\n",
    "        ratings[\"u\"+user][\"m\"+movie] = rating\n",
    "        num_ratings += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './data/movies.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-73ca5bbc75d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_movie_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-5db4bb874d03>\u001b[0m in \u001b[0;36mload_movie_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Also store the unique directors, actors, and genres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmovies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# burn metadata line\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: './data/movies.dat'"
     ]
    }
   ],
   "source": [
    "movies, directors, actors, genres = load_movie_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
